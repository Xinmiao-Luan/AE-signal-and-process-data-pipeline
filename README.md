# AE Signal and Process Data Pipeline

This repository implements a modular pipeline for **acoustic emission (AE) signals** and **process data** in additive manufacturing processes.  
It includes preprocessing, spectrogram processing, feature extraction (VAE), latent space analysis, clustering, and anomaly detection.  

---

## Folder Documentation

### DataPreprocessing
Preprocessing utilities to prepare **AE spectrograms** and **process logs** for downstream analysis.

**Modules**
- `dataClassification.py`  
  Implements segmentation into four classes:  
  1. **Building the contour** â€“ rows with consecutive `"contour"` indicators  
  2. **Transition: contour â†’ infill** â€“ gap where indicator switches from `"contour"` to `"infill"`  
  3. **Building the infill** â€“ rows with consecutive `"infill"` indicators  
  4. **Finalizing the cylinder** â€“ gap where indicator transfers from `"infill"` or `"contour"`, nozzle repositioning or z-axis adjustment  

- `dataTransfer.py` â†’ Reshapes spectrograms into fixed-size format for consistent input.  
- `frequency.py` â†’ Annotates spectrogram matrix with real frequency information.  
- `labelMatch.py` â†’ Aligns spectrogram data with quality labels via time synchronization.  
- `timeCalculator.py` & `timeTableProcess.py` â†’ Time alignment, duration calculation, and structured storage.  

**Purpose**
- Segment raw logs into phases  
- Reshape spectrograms  
- Add frequency/label context  
- Save aligned inputs for ML/QA analysis  

---

### ğŸ“ SpectrumProcessing
Utilities for **spectrogram processing and alignment** of AE signals with external process data.

**Modules**
- `drawspectrum.py` â†’ Generates standard spectrogram visualizations.  
- `drawspectrumWithMarkers.py` â†’ Adds markers highlighting labeled events.  
- `extractTimestampsFromSelectedLabels.py` â†’ Extracts time intervals from user-selected labels.  
- `time_align.py` â†’ Synchronizes AE spectrograms with process timelines.  

**Purpose**
- Generate and inspect spectrograms  
- Overlay markers for interpretability  
- Align signals with process metadata  
- Prepare data for modeling  

---

### VAE (Variational Autoencoder)
Implements **VAE training and feature extraction** for unsupervised learning from spectrograms.

**Modules**
- `VariationalAutoencodersImp.py` â†’ Core VAE (encoder, latent reparam, decoder).  
  - **Input**: spectrograms  
  - **Output**: latent variable data  
- `latentVariablesLabeledWithTimestamps.py` â†’ Aligns latent variables with timestamps and process logs.  
- `latentVariablesProcessing.py` â†’ Post-processes latent variables; includes t-SNE + visualization.  
- `plot.py` â†’ Additional visualization utilities for latent spaces/reconstructions.  

**Purpose**
- Train VAEs on spectrograms  
- Extract latent features  
- Align latent variables with sensor data  
- Visualize latent space for interpretability  

---

### LatentSpace
Utilities for **analyzing and interpreting latent variables**.

**Modules**
- `Cluster.py` â†’ Clustering utilities (extendable to KMeans, DBSCAN, etc.).  
- `PCA.py` â†’ Principal Component Analysis for dimensionality reduction.  
- `reconstructionErrorsSelection.py` â†’ Identifies and flags high reconstruction errors.  

**Purpose**
- Explore latent variables with PCA/clustering  
- Visualize embeddings in 2D/3D  
- Detect anomalies via reconstruction error analysis  

---

### Clustering
Implements **unsupervised clustering + anomaly detection** on latent features.

**Modules**
- `DBSCAN.py` â†’ Density-based clustering + outlier detection.  
- `Distance.py` â†’ Distance metric utilities (Euclidean, cosine).  
- `Isolation Forest.py` â†’ Isolation Forest anomaly detection.  
- `KMeans.py` â†’ KMeans clustering baseline.  

**Purpose**
- Group latent variables into patterns  
- Detect abnormal events via distances or isolation forests  
- Compare clustering methods for robustness  

---

## Pipeline Flow
1. DataPreprocessing
    â””â”€â”€ Clean, segment, and align AE signals with process logs
          â†“
2. SpectrumProcessing
    â””â”€â”€ Generate spectrograms, add markers, align with process metadata
          â†“
3. VAE
    â””â”€â”€ Train Variational Autoencoder and extract latent variables
          â†“
4.1 LatentSpace
    â””â”€â”€ Dimensionality reduction (PCA), clustering utilities, error analysis

4.2 Clustering
    â””â”€â”€ Apply DBSCAN, KMeans, Isolation Forest, and distance-based methods

